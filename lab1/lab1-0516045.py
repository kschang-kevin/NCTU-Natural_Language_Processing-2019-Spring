# -*- coding: utf-8 -*-
"""lab1-0516045.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gZpSRFnz72lBONukBIJ5B3BoPhrxPRFP

https://colab.research.google.com/drive/1gZpSRFnz72lBONukBIJ5B3BoPhrxPRFP
"""

import re
import math
import pandas as pd
import string
from collections import Counter

def get_corpus():
  df = pd.read_csv('https://raw.githubusercontent.com/bshmueli/108-nlp/master/reuters.csv')
  title = df.title.to_list()
  content = df.content.to_list()
  return title, content

def tokenize(document):
  remove = []
  document = document.lower() 
  words = re.split('\W+', document)[:-1]
  for i in range(len(words)):
    if not words[i] in stopwords:
      remove.append(words[i])
  return remove

def get_vocab(corpus):
  vocabulary = Counter()
  for document in corpus:
    tokens = tokenize(document)
    vocabulary.update(tokens)
  return vocabulary

def get_idf(content):
  idf = []
  for token, freq in vocab:
    count = 0
    for document in content:
       words = tokenize(document)
       if token in words:
         count += 1
    idf.append(count)
  for i in range(len(idf)):
    idf[i] = math.log(len(content)/idf[i])
  return idf

def doc2vec(doc):
  tmp = []
  tmp.append(doc)
  total_number = len(tokenize(doc))
  tokens = get_vocab(tmp)
  count = 0
  tf_idf = idf.copy()
  for token, freq in vocab:
    tf_idf[count] = tokens[token] * tf_idf[count] / total_number
    count += 1
  return tf_idf

def cosine_similarity(vec_a, vec_b):
  assert len(vec_a) == len(vec_b)
  if sum(vec_a) == 0 or sum(vec_b) == 0:
    return 0 # hack
  a_b = sum(i[0] * i[1] for i in zip(vec_a, vec_b))
  a_2 = sum([i*i for i in vec_a])
  b_2 = sum([i*i for i in vec_b])
  return a_b/(math.sqrt(a_2) * math.sqrt(b_2))

def doc_similarity(doc_a, doc_b):
  return cosine_similarity(doc2vec(doc_a), doc2vec(doc_b))

def k_similar(seed_id, k):
  seed_doc = content[seed_id]
  print('> "{}"'.format(title[seed_id]))
  similarities = [doc_similarity(seed_doc, doc) for id, doc in enumerate(content)]
  top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[-k:] # https://stackoverflow.com/questions/13070461/get-indices-of-the-top-n-values-of-a-list
  nearest = [[title[id], similarities[id]] for id in top_indices]
  print()
  for story in reversed(nearest):
    print('* "{}" ({})'.format(story[0], story[1]))

df = pd.read_csv('https://raw.githubusercontent.com/bshmueli/108-nlp/master/stopwords.txt', header=None)
stopwords = df[0].to_list()
title, content = get_corpus()
vocab = get_vocab(content).most_common(1000)
idf = get_idf(content)
k_similar(45, 5)

